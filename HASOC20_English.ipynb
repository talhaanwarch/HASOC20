{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HASOC20 English.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FwKb7_NBWjAv"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/HASOC20/blob/master/HASOC20_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd_N71KlcyII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install focal-loss\n",
        "!pip install keras-tcn\n",
        "!pip install tensorflow==2.1.0\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRdg5W5ZgMhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "771fb44f-82e8-4bb9-943b-6ff8911e2114"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Q3msMuLDpE",
        "colab_type": "text"
      },
      "source": [
        "# Import lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpTHlh_QLDL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4a18ecfb-47e3-4996-caba-ec0be646e8c1"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "\n",
        "from tensorflow.keras.layers import Embedding,GRU,LSTM,Dense,Dropout,Bidirectional,BatchNormalization,GlobalMaxPooling1D,Flatten, GlobalAveragePooling1D, MaxPooling1D,SpatialDropout1D,Input,Activation,concatenate,Conv1D,multiply\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam,Adadelta\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "# import keras\n",
        "import collections\n",
        "import numpy as np\n",
        "from focal_loss import BinaryFocalLoss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from tensorflow.keras import backend as K\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from tensorflow.keras.layers import Layer,Lambda,InputSpec\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import backend as K\n",
        "# import tensorflow as tf\n",
        "# tf.logging.set_verbosity(tf.logging.ERROR)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udk8qWz-K4cx",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx-1BQaY6rkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "966e3171-0bdd-498d-f067-1d5f3e8d5a6c"
      },
      "source": [
        "train=pd.read_csv( '/content/drive/My Drive/dataset/HASOC20/hasoc_2020_en_train.csv')\n",
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1123757263427186690</td>\n",
              "      <td>hate wen females hit ah nigga with tht bro ðŸ˜‚ðŸ˜‚,...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_2574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1123733301397733380</td>\n",
              "      <td>RT @airjunebug: When you're from the Bay but y...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_3627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1123734094108659712</td>\n",
              "      <td>RT @DonaldJTrumpJr: Dear Democrats: The Americ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_en_3108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1126951188170199049</td>\n",
              "      <td>RT @SheLoveTimothy: He ainâ€™t on drugs he just ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_en_3986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1126863510447710208</td>\n",
              "      <td>RT @TavianJordan: Summer â€˜19 Iâ€™m coming for yo...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_en_5152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id  ...                  ID\n",
              "0  1123757263427186690  ...  hasoc_2020_en_2574\n",
              "1  1123733301397733380  ...  hasoc_2020_en_3627\n",
              "2  1123734094108659712  ...  hasoc_2020_en_3108\n",
              "3  1126951188170199049  ...  hasoc_2020_en_3986\n",
              "4  1126863510447710208  ...  hasoc_2020_en_5152\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv31K9V2h41l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels=train['task1']\n",
        "train=train['text']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbpcevIl7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "stop = stopwords.words('english')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6LRT-poitAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "4af9111c-57b3-450f-81be-a578803eb0cd"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    hate wen females hit ah nigga with tht bro ðŸ˜‚ðŸ˜‚,...\n",
              "1    RT @airjunebug: When you're from the Bay but y...\n",
              "2    RT @DonaldJTrumpJr: Dear Democrats: The Americ...\n",
              "3    RT @SheLoveTimothy: He ainâ€™t on drugs he just ...\n",
              "4    RT @TavianJordan: Summer â€˜19 Iâ€™m coming for yo...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY8MVlxhggiD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "9c12390b-4215-48c5-f3cc-22dedbb5d17d"
      },
      "source": [
        "import re\n",
        "train=train.str.replace('\\d+', '')\n",
        "train= train.str.lower()\n",
        "train=train.str.replace('rt.*: ','',flags=re.DOTALL)\n",
        "\n",
        "train = train.str.replace('[^\\w\\s]','')\n",
        "#train = train.apply(lambda x : [lemmatizer.lemmatize(y) for y in w_tokenizer.tokenize(x)])\n",
        "#train = train.apply(lambda x: [item for item in x if item not in stop])\n",
        "#train = train.apply(lambda x : \" \".join(x))\n",
        "train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    hate wen females hit ah nigga with tht bro  im...\n",
              "1    when youre from the bay but youre really a ny ...\n",
              "2    the american people arent stupid they know wha...\n",
              "3    he aint on drugs he just bored i be doing the ...\n",
              "4    summer  im coming for you  no boring shit  bea...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUFczyikLeYO",
        "colab_type": "text"
      },
      "source": [
        "#Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9PjbFwJLiNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27ac08be-a120-4b4a-a829-95963e2054ce"
      },
      "source": [
        "le=LabelEncoder()\n",
        "labels=le.fit_transform(train_labels)\n",
        "print(len(labels))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYWUtZJOgbM2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f672efae-3dbe-4edf-8720-e17137c598eb"
      },
      "source": [
        "train_labels.value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HOF    1932\n",
              "NOT    1862\n",
              "Name: task1, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek_ZUjDef7ZV",
        "colab_type": "text"
      },
      "source": [
        "# Common Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdtjDLnOACbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAv_EEaQLXtY",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QomCkNlRLHPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 150\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(train)\n",
        "sequences = tokenize.texts_to_sequences(train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og1W2rCOLs4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d35f2d18-2fe4-4a30-fc04-431a00fb67b9"
      },
      "source": [
        "len(sequences_matrix),len(labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3794, 3794)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4kzu1RxLyGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7156b127-b68d-431f-c02b-bc9d825fc0e3"
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i7WSY3lMmdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_sequences = tokenize.texts_to_sequences(test)\n",
        "# X_test_sequences = sequence.pad_sequences(test_sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpzUIu4iL0PO",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UASiPIPlnZKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_path1 = \"drive/My Drive/dataset/OLID/wiki-news-300d-1M.vec\"\n",
        "embedding_path2 = \"drive/My Drive/dataset/OLID/glove/glove.840B.300d.txt\"\n",
        "embed_size = 300"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3UFPJAWL10_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTviPXodLzRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fasttext=build_matrix(embedding_path1, word_index)\n",
        "# glove_emb=build_matrix(embedding_path2, word_index)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWgNaYzPnf2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embeddings=np.mean((fasttext,glove_emb),axis=0)\n",
        "# embeddings.shape"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csvc4vdey4x9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.save('/content/drive/My Drive/dataset/OffenseEval2020/data/English/en_embeddings.npy',embeddings)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9mMo_1bP9gx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "698e718b-e9a8-4ae6-9d9c-2192ed404fc0"
      },
      "source": [
        "embeddings=np.load('/content/drive/My Drive/dataset/OffenseEval2020/data/English/en_embeddings.npy')\n",
        "embeddings.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8_AdRhffkS3",
        "colab_type": "text"
      },
      "source": [
        "# Base Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaShFhtgJ_Ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61488788-2e74-4dcd-c405-5cfdd64ef38b"
      },
      "source": [
        "train.shape,labels.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3794,), (3794,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvXD0v5mfm7M",
        "colab_type": "text"
      },
      "source": [
        "## Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7blhzyaD-xvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def logistic_param_selection(X, y, func,nfolds):\n",
        "    C= [7,8,9,10,12,15,20,25]\n",
        "    param_grid = {'C': C}\n",
        "    grid_search = GridSearchCV(make_pipeline(func, LogisticRegression(solver='lbfgs',max_iter=500,class_weight=class_weights)),\n",
        "                    param_grid={'logisticregression__C':C}, cv=nfolds,scoring='f1_macro')\n",
        "    grid_search.fit(X, y)\n",
        "    return grid_search.best_score_,grid_search.best_params_\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHFZoqkGI79e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c89805ef-d52b-4321-e3c8-d7e9cd7dcd1f"
      },
      "source": [
        "cv_score,c=logistic_param_selection(train,labels,CountVectorizer(),5)\n",
        "cv_score"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8540543614027971"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiDB13I898UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer.fit(train)\n",
        "X_train_cv = count_vectorizer.transform(train)\n",
        "#X_test_cv=  count_vectorizer.transform(test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwXHpKqo-cFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "65d34ca5-279d-4a02-d3c1-22543d4e7b5a"
      },
      "source": [
        "cv_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500,class_weight=class_weights)\n",
        "cv_classifier.fit(X_train_cv, labels)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=7,\n",
              "                   class_weight={0: 0.9818840579710145, 1: 1.018796992481203},\n",
              "                   dual=False, fit_intercept=True, intercept_scaling=1,\n",
              "                   l1_ratio=None, max_iter=500, multi_class='auto', n_jobs=None,\n",
              "                   penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
              "                   verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBx50ckVP6iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cv_test=cv_classifier.predict_proba(X_test_cv)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJDyK1lahqqG",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF word vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz1WZZEufmEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    ngram_range=(1, 4),\n",
        "    max_features=10000)\n",
        "word_vectorizer.fit(train)\n",
        "train_word_features = word_vectorizer.transform(train)\n",
        "#test_word_features = word_vectorizer.transform(test)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8hxtqPQ_KxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d946a724-8bf8-4d51-f18e-93c3d5bb3157"
      },
      "source": [
        "tfw_score,c=logistic_param_selection(train,labels,word_vectorizer,5)\n",
        "tfw_score"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.845548565812291"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04JmMwoEh4-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfw_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500)\n",
        "tfw_classifier.fit(train_word_features, labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQRy9oaBQIfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfw_test = tfw_classifier.predict_proba(test_word_features)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNSvwaG1ioq0",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF char vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_kqct6jiBq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    ngram_range=(1, 6),\n",
        "    max_features=30000)\n",
        "char_vectorizer.fit(train)\n",
        "train_char_features = char_vectorizer.transform(train)\n",
        "#test_char_features = char_vectorizer.transform(test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBU8cBQVCiAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "80090db7-3925-457d-99e5-7a88987b0463"
      },
      "source": [
        "tfc_score,c=logistic_param_selection(train,labels,char_vectorizer,5)\n",
        "tfc_score"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8540530522045847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYhzRPO0iRMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "ca15fa5a-cbbd-4c47-f1a6-1bfac64e122f"
      },
      "source": [
        "tfc_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500)\n",
        "tfc_classifier.fit(train_char_features, labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=7, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpkjinLBXX7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfc_test = tfc_classifier.predict_proba(test_char_features)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sOo5OtMQnL",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv2yPgQWL9de",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXvqlGD0L-sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(LSTM(50, return_sequences=True))(x)\n",
        "  x, x_h, x_c = Bidirectional(GRU(50, activation= 'tanh',recurrent_activation ='sigmoid',recurrent_dropout=0,\n",
        "                      unroll =False,use_bias =True,reset_after=True,return_sequences = True, return_state = True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, x_h, max_pool])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEFZUSjOryy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru1():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.2)(x)\n",
        "  x=Bidirectional(GRU(150,activation= 'tanh',recurrent_activation ='sigmoid',recurrent_dropout=0,\n",
        "                      unroll =False,use_bias =True,reset_after=True,return_sequences = True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, max_pool])\n",
        "\n",
        "\n",
        "  x=Dropout(0.1)(conc)\n",
        "  out=Dense(64, activation=\"relu\")(x)\n",
        "  out=Dense(32, activation=\"relu\")(x)\n",
        "\n",
        "  outp=Dense(1, activation=\"sigmoid\")(x)   \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t_Ph6qafOQK",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyKea_xMkrmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/zake7749/DeepToxic\n",
        "\n",
        "\n",
        "class AttentionWeightedAverage(Layer):\n",
        "    \"\"\"\n",
        "    Computes a weighted average of the different channels across timesteps.\n",
        "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.init = initializers.get('uniform')\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 initializer=self.init)\n",
        "        self.trainable_weight = [self.W]\n",
        "        super(AttentionWeightedAverage, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # computes a probability distribution over the timesteps\n",
        "        # uses 'max trick' for numerical stability\n",
        "        # reshape is done to avoid issue with Tensorflow\n",
        "        # and 1-dimensional weights\n",
        "        logits = K.dot(x, self.W)\n",
        "        x_shape = K.shape(x)\n",
        "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
        "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
        "\n",
        "        # masked timesteps have zero weight\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            ai = ai * mask\n",
        "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
        "        weighted_input = x * K.expand_dims(att_weights)\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "        if self.return_attention:\n",
        "            return [result, att_weights]\n",
        "        return result\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return self.compute_output_shape(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_len = input_shape[2]\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
        "        return (input_shape[0], output_len)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return [None] * len(input_mask)\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hovBxS5jfRbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru_attn():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(LSTM(50, activation= 'tanh',recurrent_activation ='sigmoid',recurrent_dropout=0,\n",
        "                      unroll =False,use_bias =True,return_sequences = True))(x)\n",
        "  x = Bidirectional(GRU(50, activation= 'tanh',recurrent_activation ='sigmoid',recurrent_dropout=0,\n",
        "                      unroll =False,use_bias =True,reset_after=True,return_sequences = True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  last = Lambda(lambda t: t[:, -1])(x)\n",
        "  attn = AttentionWeightedAverage()(x)\n",
        "  conc = concatenate([avg_pool,  max_pool,last,attn])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I34DRPLqTVru",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-euqTedTWjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tcn import TCN\n",
        "\n",
        "def wave_net_activation(x):\n",
        "    # type: (Layer) -> Layer\n",
        "    \"\"\"This method defines the activation used for WaveNet\n",
        "    described in https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n",
        "    Args:\n",
        "        x: The layer we want to apply the activation to\n",
        "    Returns:\n",
        "        A new layer with the wavenet activation applied\n",
        "    \"\"\"\n",
        "    tanh_out = Activation('tanh')(x)\n",
        "    sigm_out = Activation('sigmoid')(x)\n",
        "    return multiply([tanh_out, sigm_out])\n",
        "\n",
        "def model_tcn(embedding_matrix):\n",
        "    \n",
        "    inp = Input(shape=(max_len,))\n",
        "    x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True ,name = 'tnc1')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, name = 'tnc2')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    #x = TCN(32,dilations = [1, 2, 4], return_sequences=True, activation = 'wavenet',name = 'tnc3')(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dense(32, activation=\"relu\")(conc)\n",
        "\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNc6xxspBcTG",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAgtTt9IBfMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_filters=128\n",
        "def model_kim():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  emb = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  # Specify each convolution layer and their kernel siz i.e. n-grams \n",
        "  conv1_1 = Conv1D(filters=conv_filters, kernel_size=3)(emb)\n",
        "  btch1_1 = BatchNormalization()(conv1_1)\n",
        "  drp1_1  = Dropout(0.2)(btch1_1)\n",
        "  actv1_1 = Activation('relu')(drp1_1)\n",
        "  glmp1_1 = GlobalMaxPooling1D()(actv1_1)\n",
        "\n",
        "  conv1_2 = Conv1D(filters=conv_filters, kernel_size=4)(emb)\n",
        "  btch1_2 = BatchNormalization()(conv1_2)\n",
        "  drp1_2  = Dropout(0.2)(btch1_2)\n",
        "  actv1_2 = Activation('relu')(drp1_2)\n",
        "  glmp1_2 = GlobalMaxPooling1D()(actv1_2)\n",
        "\n",
        "  conv1_3 = Conv1D(filters=conv_filters, kernel_size=5)(emb)\n",
        "  btch1_3 = BatchNormalization()(conv1_3)\n",
        "  drp1_3  = Dropout(0.2)(btch1_3)\n",
        "  actv1_3 = Activation('relu')(drp1_3)\n",
        "  glmp1_3 = GlobalMaxPooling1D()(actv1_3)\n",
        "\n",
        "  conv1_4 = Conv1D(filters=conv_filters, kernel_size=6)(emb)\n",
        "  btch1_4 = BatchNormalization()(conv1_4)\n",
        "  drp1_4  = Dropout(0.2)(btch1_4)\n",
        "  actv1_4 = Activation('relu')(drp1_4)\n",
        "  glmp1_4 = GlobalMaxPooling1D()(actv1_4)\n",
        "\n",
        "  # Gather all convolution layers\n",
        "  cnct = concatenate([glmp1_1, glmp1_2, glmp1_3, glmp1_4], axis=1)\n",
        "  drp1 = Dropout(0.2)(cnct)\n",
        "\n",
        "  dns1  = Dense(32, activation='relu')(drp1)\n",
        "  btch1 = BatchNormalization()(dns1)\n",
        "  drp2  = Dropout(0.2)(btch1)\n",
        "\n",
        "  out = Dense(1, activation='sigmoid')(drp2)   \n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b46h68vVq4Wp",
        "colab_type": "text"
      },
      "source": [
        "##RNN_CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyFfCHOxq6lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def model_gru_cnn():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.5)(x)\n",
        "  x = Bidirectional(LSTM(128, activation= 'tanh',recurrent_activation ='sigmoid',recurrent_dropout=0,\n",
        "                      unroll =False,use_bias =True,return_sequences = True))(x)\n",
        "  x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  x = concatenate([avg_pool, max_pool])\n",
        "  x = Dense(10, activation = \"relu\")(x)\n",
        "\n",
        "  outp=Dense(1, activation=\"sigmoid\")(x)   \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCuBpqkNx8L",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHowSR5qiI-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "clr=ReduceLROnPlateau(monitor='val_loss', factor=0.3,patience=3, min_lr=0.000001)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUygUis5N2yN",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZpadAhoiq4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44b9af6a-7b66-4b7a-dc34-26a8656c631c"
      },
      "source": [
        "sequences_matrix.shape,labels.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3794, 150), (3794,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdwYL0fG3kQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81ddf9a7-5dc2-4825-c31f-9eb8faf3b8c9"
      },
      "source": [
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "gru_scores = []\n",
        "gru_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  gru_model=model_gru()\n",
        "  \n",
        "  gru_model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = gru_model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        " #/ gru_test.append(gru_model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  gru_scores.append(f1)\n",
        "  tf.keras.backend.clear_session()\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 8s - loss: 0.1698 - accuracy: 0.5671 - val_loss: 0.1618 - val_accuracy: 0.6034\n",
            "Epoch 2/10\n",
            "3035/3035 - 2s - loss: 0.1548 - accuracy: 0.6583 - val_loss: 0.1434 - val_accuracy: 0.6877\n",
            "Epoch 3/10\n",
            "3035/3035 - 2s - loss: 0.1368 - accuracy: 0.7203 - val_loss: 0.1299 - val_accuracy: 0.7510\n",
            "Epoch 4/10\n",
            "3035/3035 - 2s - loss: 0.1214 - accuracy: 0.7634 - val_loss: 0.1193 - val_accuracy: 0.7734\n",
            "Epoch 5/10\n",
            "3035/3035 - 2s - loss: 0.1091 - accuracy: 0.8000 - val_loss: 0.1123 - val_accuracy: 0.7931\n",
            "Epoch 6/10\n",
            "3035/3035 - 2s - loss: 0.1009 - accuracy: 0.8244 - val_loss: 0.1097 - val_accuracy: 0.8076\n",
            "Epoch 7/10\n",
            "3035/3035 - 2s - loss: 0.0901 - accuracy: 0.8468 - val_loss: 0.1095 - val_accuracy: 0.8155\n",
            "Epoch 8/10\n",
            "3035/3035 - 2s - loss: 0.0774 - accuracy: 0.8751 - val_loss: 0.1126 - val_accuracy: 0.8024\n",
            "Epoch 9/10\n",
            "3035/3035 - 2s - loss: 0.0700 - accuracy: 0.8956 - val_loss: 0.1200 - val_accuracy: 0.8037\n",
            "Epoch 10/10\n",
            "3035/3035 - 2s - loss: 0.0628 - accuracy: 0.9061 - val_loss: 0.1256 - val_accuracy: 0.7918\n",
            "759/759 [==============================] - 1s 2ms/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 8s - loss: 0.1677 - accuracy: 0.5809 - val_loss: 0.1603 - val_accuracy: 0.6350\n",
            "Epoch 2/10\n",
            "3035/3035 - 2s - loss: 0.1507 - accuracy: 0.6837 - val_loss: 0.1510 - val_accuracy: 0.6627\n",
            "Epoch 3/10\n",
            "3035/3035 - 2s - loss: 0.1313 - accuracy: 0.7417 - val_loss: 0.1377 - val_accuracy: 0.7009\n",
            "Epoch 4/10\n",
            "3035/3035 - 2s - loss: 0.1196 - accuracy: 0.7677 - val_loss: 0.1303 - val_accuracy: 0.7549\n",
            "Epoch 5/10\n",
            "3035/3035 - 2s - loss: 0.1077 - accuracy: 0.8076 - val_loss: 0.1302 - val_accuracy: 0.7826\n",
            "Epoch 6/10\n",
            "3035/3035 - 2s - loss: 0.0954 - accuracy: 0.8379 - val_loss: 0.1522 - val_accuracy: 0.7708\n",
            "Epoch 7/10\n",
            "3035/3035 - 2s - loss: 0.0901 - accuracy: 0.8498 - val_loss: 0.1290 - val_accuracy: 0.7536\n",
            "Epoch 8/10\n",
            "3035/3035 - 2s - loss: 0.0855 - accuracy: 0.8557 - val_loss: 0.1204 - val_accuracy: 0.8011\n",
            "Epoch 9/10\n",
            "3035/3035 - 2s - loss: 0.0727 - accuracy: 0.8834 - val_loss: 0.1441 - val_accuracy: 0.7971\n",
            "Epoch 10/10\n",
            "3035/3035 - 2s - loss: 0.0665 - accuracy: 0.8946 - val_loss: 0.1355 - val_accuracy: 0.7997\n",
            "759/759 [==============================] - 2s 2ms/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 8s - loss: 0.1686 - accuracy: 0.5865 - val_loss: 0.1590 - val_accuracy: 0.6627\n",
            "Epoch 2/10\n",
            "3035/3035 - 2s - loss: 0.1509 - accuracy: 0.6781 - val_loss: 0.1487 - val_accuracy: 0.6680\n",
            "Epoch 3/10\n",
            "3035/3035 - 2s - loss: 0.1314 - accuracy: 0.7466 - val_loss: 0.1296 - val_accuracy: 0.7510\n",
            "Epoch 4/10\n",
            "3035/3035 - 2s - loss: 0.1186 - accuracy: 0.7756 - val_loss: 0.1262 - val_accuracy: 0.7378\n",
            "Epoch 5/10\n",
            "3035/3035 - 2s - loss: 0.1085 - accuracy: 0.8030 - val_loss: 0.1163 - val_accuracy: 0.7866\n",
            "Epoch 6/10\n",
            "3035/3035 - 2s - loss: 0.0992 - accuracy: 0.8260 - val_loss: 0.1350 - val_accuracy: 0.6943\n",
            "Epoch 7/10\n",
            "3035/3035 - 2s - loss: 0.0927 - accuracy: 0.8376 - val_loss: 0.1113 - val_accuracy: 0.8037\n",
            "Epoch 8/10\n",
            "3035/3035 - 2s - loss: 0.0775 - accuracy: 0.8787 - val_loss: 0.1162 - val_accuracy: 0.8116\n",
            "Epoch 9/10\n",
            "3035/3035 - 2s - loss: 0.0724 - accuracy: 0.8817 - val_loss: 0.1172 - val_accuracy: 0.7852\n",
            "Epoch 10/10\n",
            "3035/3035 - 2s - loss: 0.0640 - accuracy: 0.8985 - val_loss: 0.1232 - val_accuracy: 0.7813\n",
            "759/759 [==============================] - 1s 2ms/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 8s - loss: 0.1684 - accuracy: 0.5750 - val_loss: 0.1642 - val_accuracy: 0.5705\n",
            "Epoch 2/10\n",
            "3035/3035 - 2s - loss: 0.1512 - accuracy: 0.6662 - val_loss: 0.1405 - val_accuracy: 0.7141\n",
            "Epoch 3/10\n",
            "3035/3035 - 2s - loss: 0.1328 - accuracy: 0.7321 - val_loss: 0.1284 - val_accuracy: 0.7536\n",
            "Epoch 4/10\n",
            "3035/3035 - 2s - loss: 0.1196 - accuracy: 0.7713 - val_loss: 0.1231 - val_accuracy: 0.7760\n",
            "Epoch 5/10\n",
            "3035/3035 - 2s - loss: 0.1051 - accuracy: 0.8099 - val_loss: 0.1221 - val_accuracy: 0.7404\n",
            "Epoch 6/10\n",
            "3035/3035 - 2s - loss: 0.0976 - accuracy: 0.8260 - val_loss: 0.1097 - val_accuracy: 0.7958\n",
            "Epoch 7/10\n",
            "3035/3035 - 2s - loss: 0.0852 - accuracy: 0.8616 - val_loss: 0.1139 - val_accuracy: 0.7997\n",
            "Epoch 8/10\n",
            "3035/3035 - 2s - loss: 0.0789 - accuracy: 0.8669 - val_loss: 0.1147 - val_accuracy: 0.7931\n",
            "Epoch 9/10\n",
            "3035/3035 - 2s - loss: 0.0700 - accuracy: 0.8909 - val_loss: 0.1190 - val_accuracy: 0.7971\n",
            "Epoch 10/10\n",
            "3035/3035 - 2s - loss: 0.0589 - accuracy: 0.9124 - val_loss: 0.1208 - val_accuracy: 0.8103\n",
            "759/759 [==============================] - 1s 2ms/sample\n",
            "Train on 3036 samples, validate on 758 samples\n",
            "Epoch 1/10\n",
            "3036/3036 - 8s - loss: 0.1701 - accuracy: 0.5613 - val_loss: 0.1714 - val_accuracy: 0.5198\n",
            "Epoch 2/10\n",
            "3036/3036 - 2s - loss: 0.1527 - accuracy: 0.6716 - val_loss: 0.1474 - val_accuracy: 0.6768\n",
            "Epoch 3/10\n",
            "3036/3036 - 2s - loss: 0.1320 - accuracy: 0.7368 - val_loss: 0.1361 - val_accuracy: 0.7058\n",
            "Epoch 4/10\n",
            "3036/3036 - 2s - loss: 0.1181 - accuracy: 0.7734 - val_loss: 0.1316 - val_accuracy: 0.7612\n",
            "Epoch 5/10\n",
            "3036/3036 - 2s - loss: 0.1117 - accuracy: 0.7945 - val_loss: 0.1356 - val_accuracy: 0.7361\n",
            "Epoch 6/10\n",
            "3036/3036 - 2s - loss: 0.0992 - accuracy: 0.8317 - val_loss: 0.1164 - val_accuracy: 0.7982\n",
            "Epoch 7/10\n",
            "3036/3036 - 2s - loss: 0.0866 - accuracy: 0.8564 - val_loss: 0.1197 - val_accuracy: 0.8047\n",
            "Epoch 8/10\n",
            "3036/3036 - 2s - loss: 0.0766 - accuracy: 0.8748 - val_loss: 0.1282 - val_accuracy: 0.7691\n",
            "Epoch 9/10\n",
            "3036/3036 - 2s - loss: 0.0691 - accuracy: 0.8910 - val_loss: 0.1285 - val_accuracy: 0.8047\n",
            "Epoch 10/10\n",
            "3036/3036 - 2s - loss: 0.0594 - accuracy: 0.9107 - val_loss: 0.1374 - val_accuracy: 0.7850\n",
            "758/758 [==============================] - 1s 2ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKKs8iWX570n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "361221ab-cb23-4463-fc6a-9fdbe8ba02ce"
      },
      "source": [
        "np.mean(gru_scores)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7934497667600902"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcJjKG_6sJAC",
        "colab_type": "text"
      },
      "source": [
        "##GRU 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APrVpJEGsK0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5dbd9570-1a93-4cc1-ed93-8c22a5f9aa6a"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "gru_scores1 = []\n",
        "gru_test1=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  gru_model=model_gru1()\n",
        "  \n",
        "  gru_model.fit(sequences_matrix[train], labels[train],batch_size=128,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]))\n",
        "  y_pred = gru_model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  #gru_test1.append(gru_model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  gru_scores1.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 4s - loss: 0.1683 - accuracy: 0.5783 - val_loss: 0.1567 - val_accuracy: 0.6640\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1503 - accuracy: 0.6896 - val_loss: 0.1430 - val_accuracy: 0.7167\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1389 - accuracy: 0.7249 - val_loss: 0.1338 - val_accuracy: 0.7418\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1254 - accuracy: 0.7697 - val_loss: 0.1257 - val_accuracy: 0.7563\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.1154 - accuracy: 0.8000 - val_loss: 0.1196 - val_accuracy: 0.7813\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.1058 - accuracy: 0.8264 - val_loss: 0.1153 - val_accuracy: 0.7800\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0965 - accuracy: 0.8458 - val_loss: 0.1110 - val_accuracy: 0.8037\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0888 - accuracy: 0.8662 - val_loss: 0.1072 - val_accuracy: 0.8195\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0809 - accuracy: 0.8830 - val_loss: 0.1095 - val_accuracy: 0.8076\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0754 - accuracy: 0.8936 - val_loss: 0.1068 - val_accuracy: 0.8195\n",
            "759/759 [==============================] - 1s 811us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 4s - loss: 0.1664 - accuracy: 0.5941 - val_loss: 0.1573 - val_accuracy: 0.6561\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1486 - accuracy: 0.6969 - val_loss: 0.1505 - val_accuracy: 0.6891\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1339 - accuracy: 0.7430 - val_loss: 0.1402 - val_accuracy: 0.6864\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1218 - accuracy: 0.7694 - val_loss: 0.1348 - val_accuracy: 0.7022\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.1131 - accuracy: 0.8003 - val_loss: 0.1273 - val_accuracy: 0.7523\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.1034 - accuracy: 0.8178 - val_loss: 0.1283 - val_accuracy: 0.7642\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0943 - accuracy: 0.8422 - val_loss: 0.1248 - val_accuracy: 0.7312\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0907 - accuracy: 0.8514 - val_loss: 0.1223 - val_accuracy: 0.7931\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0811 - accuracy: 0.8811 - val_loss: 0.1176 - val_accuracy: 0.7642\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0764 - accuracy: 0.8843 - val_loss: 0.1214 - val_accuracy: 0.8090\n",
            "759/759 [==============================] - 1s 1ms/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 4s - loss: 0.1717 - accuracy: 0.5502 - val_loss: 0.1583 - val_accuracy: 0.6601\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1512 - accuracy: 0.6936 - val_loss: 0.1457 - val_accuracy: 0.7075\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1381 - accuracy: 0.7351 - val_loss: 0.1367 - val_accuracy: 0.7312\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1269 - accuracy: 0.7611 - val_loss: 0.1282 - val_accuracy: 0.7497\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.1151 - accuracy: 0.7868 - val_loss: 0.1213 - val_accuracy: 0.7708\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.1064 - accuracy: 0.8145 - val_loss: 0.1171 - val_accuracy: 0.7747\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0991 - accuracy: 0.8362 - val_loss: 0.1129 - val_accuracy: 0.7892\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0907 - accuracy: 0.8557 - val_loss: 0.1083 - val_accuracy: 0.7997\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0849 - accuracy: 0.8643 - val_loss: 0.1077 - val_accuracy: 0.8142\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0767 - accuracy: 0.8847 - val_loss: 0.1052 - val_accuracy: 0.8129\n",
            "759/759 [==============================] - 1s 798us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 5s - loss: 0.1693 - accuracy: 0.5763 - val_loss: 0.1562 - val_accuracy: 0.7075\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1514 - accuracy: 0.6909 - val_loss: 0.1463 - val_accuracy: 0.6812\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1378 - accuracy: 0.7301 - val_loss: 0.1337 - val_accuracy: 0.7444\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1271 - accuracy: 0.7555 - val_loss: 0.1268 - val_accuracy: 0.7628\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.1141 - accuracy: 0.8013 - val_loss: 0.1221 - val_accuracy: 0.7549\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.1052 - accuracy: 0.8231 - val_loss: 0.1156 - val_accuracy: 0.7879\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.1003 - accuracy: 0.8339 - val_loss: 0.1164 - val_accuracy: 0.7866\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0925 - accuracy: 0.8590 - val_loss: 0.1089 - val_accuracy: 0.8142\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0843 - accuracy: 0.8728 - val_loss: 0.1077 - val_accuracy: 0.8169\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0762 - accuracy: 0.8880 - val_loss: 0.1049 - val_accuracy: 0.8221\n",
            "759/759 [==============================] - 1s 832us/sample\n",
            "Train on 3036 samples, validate on 758 samples\n",
            "Epoch 1/10\n",
            "3036/3036 - 4s - loss: 0.1668 - accuracy: 0.5926 - val_loss: 0.1615 - val_accuracy: 0.6016\n",
            "Epoch 2/10\n",
            "3036/3036 - 1s - loss: 0.1496 - accuracy: 0.6924 - val_loss: 0.1483 - val_accuracy: 0.6715\n",
            "Epoch 3/10\n",
            "3036/3036 - 1s - loss: 0.1352 - accuracy: 0.7401 - val_loss: 0.1338 - val_accuracy: 0.7335\n",
            "Epoch 4/10\n",
            "3036/3036 - 1s - loss: 0.1228 - accuracy: 0.7750 - val_loss: 0.1272 - val_accuracy: 0.7480\n",
            "Epoch 5/10\n",
            "3036/3036 - 1s - loss: 0.1119 - accuracy: 0.7984 - val_loss: 0.1200 - val_accuracy: 0.7678\n",
            "Epoch 6/10\n",
            "3036/3036 - 1s - loss: 0.1026 - accuracy: 0.8267 - val_loss: 0.1151 - val_accuracy: 0.7797\n",
            "Epoch 7/10\n",
            "3036/3036 - 1s - loss: 0.0960 - accuracy: 0.8370 - val_loss: 0.1130 - val_accuracy: 0.7876\n",
            "Epoch 8/10\n",
            "3036/3036 - 1s - loss: 0.0865 - accuracy: 0.8643 - val_loss: 0.1117 - val_accuracy: 0.7929\n",
            "Epoch 9/10\n",
            "3036/3036 - 1s - loss: 0.0795 - accuracy: 0.8791 - val_loss: 0.1123 - val_accuracy: 0.8074\n",
            "Epoch 10/10\n",
            "3036/3036 - 1s - loss: 0.0713 - accuracy: 0.8986 - val_loss: 0.1168 - val_accuracy: 0.8074\n",
            "758/758 [==============================] - 1s 1ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XTLgwdCt1WM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "804d3e20-ccba-4c78-ed1f-6dc1ae7f2ed4"
      },
      "source": [
        "np.mean(gru_scores1)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8130888015447051"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaW-Uq0Kldp4",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XULscbNL6FiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a68d7e6a-ec43-4add-d1a8-4be70afd3c09"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "atten_scores = []\n",
        "atten_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  attn_gru_model=model_gru_attn()\n",
        "  \n",
        "  attn_gru_model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = attn_gru_model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  #atten_test.append(attn_gru_model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  atten_scores.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 8s - loss: 0.1693 - accuracy: 0.5647 - val_loss: 0.1583 - val_accuracy: 0.6482\n",
            "Epoch 2/10\n",
            "3035/3035 - 2s - loss: 0.1529 - accuracy: 0.6649 - val_loss: 0.1457 - val_accuracy: 0.6838\n",
            "Epoch 3/10\n",
            "3035/3035 - 2s - loss: 0.1349 - accuracy: 0.7292 - val_loss: 0.1316 - val_accuracy: 0.7325\n",
            "Epoch 4/10\n",
            "3035/3035 - 2s - loss: 0.1227 - accuracy: 0.7624 - val_loss: 0.1199 - val_accuracy: 0.7708\n",
            "Epoch 5/10\n",
            "3035/3035 - 2s - loss: 0.1072 - accuracy: 0.8119 - val_loss: 0.1148 - val_accuracy: 0.7918\n",
            "Epoch 6/10\n",
            "3035/3035 - 2s - loss: 0.0974 - accuracy: 0.8300 - val_loss: 0.1140 - val_accuracy: 0.7747\n",
            "Epoch 7/10\n",
            "3035/3035 - 2s - loss: 0.0872 - accuracy: 0.8491 - val_loss: 0.1087 - val_accuracy: 0.8155\n",
            "Epoch 8/10\n",
            "3035/3035 - 2s - loss: 0.0791 - accuracy: 0.8712 - val_loss: 0.1466 - val_accuracy: 0.7233\n",
            "Epoch 9/10\n",
            "3035/3035 - 2s - loss: 0.0705 - accuracy: 0.8840 - val_loss: 0.1211 - val_accuracy: 0.7971\n",
            "Epoch 10/10\n",
            "3035/3035 - 2s - loss: 0.0610 - accuracy: 0.9051 - val_loss: 0.1311 - val_accuracy: 0.7958\n",
            "759/759 [==============================] - 1s 2ms/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 8s - loss: 0.1687 - accuracy: 0.5779 - val_loss: 0.1614 - val_accuracy: 0.6232\n",
            "Epoch 2/10\n",
            "3035/3035 - 2s - loss: 0.1484 - accuracy: 0.6778 - val_loss: 0.1504 - val_accuracy: 0.6838\n",
            "Epoch 3/10\n",
            "3035/3035 - 2s - loss: 0.1285 - accuracy: 0.7334 - val_loss: 0.1414 - val_accuracy: 0.7194\n",
            "Epoch 4/10\n",
            "3035/3035 - 2s - loss: 0.1179 - accuracy: 0.7684 - val_loss: 0.1280 - val_accuracy: 0.7470\n",
            "Epoch 5/10\n",
            "3035/3035 - 2s - loss: 0.1028 - accuracy: 0.8158 - val_loss: 0.1325 - val_accuracy: 0.7892\n",
            "Epoch 6/10\n",
            "3035/3035 - 2s - loss: 0.0921 - accuracy: 0.8465 - val_loss: 0.1312 - val_accuracy: 0.7997\n",
            "Epoch 7/10\n",
            "3035/3035 - 2s - loss: 0.0845 - accuracy: 0.8554 - val_loss: 0.1366 - val_accuracy: 0.7945\n",
            "Epoch 8/10\n",
            "3035/3035 - 2s - loss: 0.0744 - accuracy: 0.8807 - val_loss: 0.1362 - val_accuracy: 0.8103\n",
            "Epoch 9/10\n",
            "3035/3035 - 2s - loss: 0.0688 - accuracy: 0.8870 - val_loss: 0.1314 - val_accuracy: 0.7826\n",
            "Epoch 10/10\n",
            "3035/3035 - 2s - loss: 0.0650 - accuracy: 0.8985 - val_loss: 0.1418 - val_accuracy: 0.8024\n",
            "759/759 [==============================] - 1s 2ms/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 8s - loss: 0.1696 - accuracy: 0.5723 - val_loss: 0.1609 - val_accuracy: 0.6733\n",
            "Epoch 2/10\n",
            "3035/3035 - 2s - loss: 0.1536 - accuracy: 0.6738 - val_loss: 0.1601 - val_accuracy: 0.6324\n",
            "Epoch 3/10\n",
            "3035/3035 - 2s - loss: 0.1363 - accuracy: 0.7269 - val_loss: 0.1333 - val_accuracy: 0.7312\n",
            "Epoch 4/10\n",
            "3035/3035 - 2s - loss: 0.1195 - accuracy: 0.7720 - val_loss: 0.1285 - val_accuracy: 0.7444\n",
            "Epoch 5/10\n",
            "3035/3035 - 2s - loss: 0.1093 - accuracy: 0.7977 - val_loss: 0.1177 - val_accuracy: 0.7734\n",
            "Epoch 6/10\n",
            "3035/3035 - 2s - loss: 0.0978 - accuracy: 0.8290 - val_loss: 0.1073 - val_accuracy: 0.8142\n",
            "Epoch 7/10\n",
            "3035/3035 - 2s - loss: 0.0861 - accuracy: 0.8557 - val_loss: 0.1070 - val_accuracy: 0.8169\n",
            "Epoch 8/10\n",
            "3035/3035 - 2s - loss: 0.0768 - accuracy: 0.8695 - val_loss: 0.1121 - val_accuracy: 0.7866\n",
            "Epoch 9/10\n",
            "3035/3035 - 2s - loss: 0.0692 - accuracy: 0.8853 - val_loss: 0.1138 - val_accuracy: 0.7918\n",
            "Epoch 10/10\n",
            "3035/3035 - 2s - loss: 0.0606 - accuracy: 0.8946 - val_loss: 0.1206 - val_accuracy: 0.7839\n",
            "759/759 [==============================] - 1s 2ms/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 8s - loss: 0.1691 - accuracy: 0.5713 - val_loss: 0.1588 - val_accuracy: 0.6706\n",
            "Epoch 2/10\n",
            "3035/3035 - 2s - loss: 0.1515 - accuracy: 0.6705 - val_loss: 0.1419 - val_accuracy: 0.7009\n",
            "Epoch 3/10\n",
            "3035/3035 - 2s - loss: 0.1337 - accuracy: 0.7384 - val_loss: 0.1287 - val_accuracy: 0.7365\n",
            "Epoch 4/10\n",
            "3035/3035 - 2s - loss: 0.1176 - accuracy: 0.7786 - val_loss: 0.1225 - val_accuracy: 0.7444\n",
            "Epoch 5/10\n",
            "3035/3035 - 2s - loss: 0.1056 - accuracy: 0.8138 - val_loss: 0.1122 - val_accuracy: 0.7905\n",
            "Epoch 6/10\n",
            "3035/3035 - 2s - loss: 0.0956 - accuracy: 0.8402 - val_loss: 0.1114 - val_accuracy: 0.7958\n",
            "Epoch 7/10\n",
            "3035/3035 - 2s - loss: 0.0869 - accuracy: 0.8530 - val_loss: 0.1093 - val_accuracy: 0.8050\n",
            "Epoch 8/10\n",
            "3035/3035 - 2s - loss: 0.0794 - accuracy: 0.8735 - val_loss: 0.1103 - val_accuracy: 0.7984\n",
            "Epoch 9/10\n",
            "3035/3035 - 2s - loss: 0.0682 - accuracy: 0.8909 - val_loss: 0.1127 - val_accuracy: 0.7997\n",
            "Epoch 10/10\n",
            "3035/3035 - 2s - loss: 0.0611 - accuracy: 0.9087 - val_loss: 0.1229 - val_accuracy: 0.7945\n",
            "759/759 [==============================] - 2s 2ms/sample\n",
            "Train on 3036 samples, validate on 758 samples\n",
            "Epoch 1/10\n",
            "3036/3036 - 8s - loss: 0.1677 - accuracy: 0.6021 - val_loss: 0.1625 - val_accuracy: 0.6029\n",
            "Epoch 2/10\n",
            "3036/3036 - 2s - loss: 0.1502 - accuracy: 0.6825 - val_loss: 0.1434 - val_accuracy: 0.7071\n",
            "Epoch 3/10\n",
            "3036/3036 - 2s - loss: 0.1305 - accuracy: 0.7437 - val_loss: 0.1282 - val_accuracy: 0.7427\n",
            "Epoch 4/10\n",
            "3036/3036 - 2s - loss: 0.1140 - accuracy: 0.7922 - val_loss: 0.1220 - val_accuracy: 0.7639\n",
            "Epoch 5/10\n",
            "3036/3036 - 2s - loss: 0.1064 - accuracy: 0.8086 - val_loss: 0.1165 - val_accuracy: 0.7876\n",
            "Epoch 6/10\n",
            "3036/3036 - 2s - loss: 0.0944 - accuracy: 0.8370 - val_loss: 0.1155 - val_accuracy: 0.8047\n",
            "Epoch 7/10\n",
            "3036/3036 - 2s - loss: 0.0880 - accuracy: 0.8554 - val_loss: 0.1175 - val_accuracy: 0.8021\n",
            "Epoch 8/10\n",
            "3036/3036 - 2s - loss: 0.0788 - accuracy: 0.8732 - val_loss: 0.1270 - val_accuracy: 0.7823\n",
            "Epoch 9/10\n",
            "3036/3036 - 2s - loss: 0.0699 - accuracy: 0.8857 - val_loss: 0.1392 - val_accuracy: 0.7823\n",
            "Epoch 10/10\n",
            "3036/3036 - 2s - loss: 0.0582 - accuracy: 0.9124 - val_loss: 0.1305 - val_accuracy: 0.8008\n",
            "758/758 [==============================] - 1s 2ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo1Ec10_FbH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83edbc3e-bc1a-4b43-9120-5ee149351640"
      },
      "source": [
        " np.mean(atten_scores)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.794886579582516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlFNurr4T1rh",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKtfxHFBT2wB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "474c8812-bf7b-4223-d194-65d84d64a22c"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "tcn_scores = []\n",
        "tcn_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  model=model_tcn(embeddings)\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  #tcn_test.append(model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  tcn_scores.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 4s - loss: 0.1753 - accuracy: 0.5249 - val_loss: 0.1707 - val_accuracy: 0.5599\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1688 - accuracy: 0.5756 - val_loss: 0.1659 - val_accuracy: 0.5863\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1432 - accuracy: 0.6873 - val_loss: 0.1297 - val_accuracy: 0.7233\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1243 - accuracy: 0.7644 - val_loss: 0.1157 - val_accuracy: 0.7787\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.1100 - accuracy: 0.8046 - val_loss: 0.1225 - val_accuracy: 0.7628\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.0923 - accuracy: 0.8524 - val_loss: 0.1050 - val_accuracy: 0.8274\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0730 - accuracy: 0.8942 - val_loss: 0.1113 - val_accuracy: 0.8182\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0605 - accuracy: 0.9160 - val_loss: 0.1249 - val_accuracy: 0.8169\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0481 - accuracy: 0.9318 - val_loss: 0.1230 - val_accuracy: 0.8208\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0278 - accuracy: 0.9677 - val_loss: 0.1525 - val_accuracy: 0.8195\n",
            "759/759 [==============================] - 0s 569us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 3s - loss: 0.1767 - accuracy: 0.5371 - val_loss: 0.1719 - val_accuracy: 0.5415\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1690 - accuracy: 0.5723 - val_loss: 0.1620 - val_accuracy: 0.6443\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1467 - accuracy: 0.6827 - val_loss: 0.1322 - val_accuracy: 0.7220\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1228 - accuracy: 0.7700 - val_loss: 0.1231 - val_accuracy: 0.7813\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.0974 - accuracy: 0.8386 - val_loss: 0.1294 - val_accuracy: 0.7708\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.0854 - accuracy: 0.8672 - val_loss: 0.1100 - val_accuracy: 0.8182\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0707 - accuracy: 0.8926 - val_loss: 0.1409 - val_accuracy: 0.7391\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0544 - accuracy: 0.9315 - val_loss: 0.1561 - val_accuracy: 0.8195\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0450 - accuracy: 0.9423 - val_loss: 0.1509 - val_accuracy: 0.8024\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0266 - accuracy: 0.9694 - val_loss: 0.1760 - val_accuracy: 0.7958\n",
            "759/759 [==============================] - 0s 554us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 3s - loss: 0.1746 - accuracy: 0.5189 - val_loss: 0.1698 - val_accuracy: 0.6074\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1673 - accuracy: 0.5819 - val_loss: 0.1565 - val_accuracy: 0.6667\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1379 - accuracy: 0.7249 - val_loss: 0.1169 - val_accuracy: 0.7852\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1052 - accuracy: 0.8204 - val_loss: 0.1027 - val_accuracy: 0.8366\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.0929 - accuracy: 0.8534 - val_loss: 0.1086 - val_accuracy: 0.8235\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.0800 - accuracy: 0.8741 - val_loss: 0.1131 - val_accuracy: 0.8129\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0670 - accuracy: 0.9008 - val_loss: 0.1390 - val_accuracy: 0.7602\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0495 - accuracy: 0.9334 - val_loss: 0.1214 - val_accuracy: 0.8432\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0343 - accuracy: 0.9549 - val_loss: 0.1321 - val_accuracy: 0.8274\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0248 - accuracy: 0.9694 - val_loss: 0.1529 - val_accuracy: 0.8274\n",
            "759/759 [==============================] - 0s 544us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 4s - loss: 0.1742 - accuracy: 0.5275 - val_loss: 0.1733 - val_accuracy: 0.5072\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1637 - accuracy: 0.6194 - val_loss: 0.1518 - val_accuracy: 0.7101\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1359 - accuracy: 0.7305 - val_loss: 0.1302 - val_accuracy: 0.7444\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1079 - accuracy: 0.8161 - val_loss: 0.1080 - val_accuracy: 0.8103\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.0921 - accuracy: 0.8474 - val_loss: 0.1213 - val_accuracy: 0.7563\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.0766 - accuracy: 0.8847 - val_loss: 0.1313 - val_accuracy: 0.8037\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0674 - accuracy: 0.8919 - val_loss: 0.1167 - val_accuracy: 0.8116\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0422 - accuracy: 0.9466 - val_loss: 0.1353 - val_accuracy: 0.8155\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0305 - accuracy: 0.9631 - val_loss: 0.1525 - val_accuracy: 0.7971\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0223 - accuracy: 0.9740 - val_loss: 0.1813 - val_accuracy: 0.8103\n",
            "759/759 [==============================] - 0s 563us/sample\n",
            "Train on 3036 samples, validate on 758 samples\n",
            "Epoch 1/10\n",
            "3036/3036 - 4s - loss: 0.1775 - accuracy: 0.5349 - val_loss: 0.1668 - val_accuracy: 0.6016\n",
            "Epoch 2/10\n",
            "3036/3036 - 1s - loss: 0.1582 - accuracy: 0.6406 - val_loss: 0.1478 - val_accuracy: 0.6755\n",
            "Epoch 3/10\n",
            "3036/3036 - 1s - loss: 0.1326 - accuracy: 0.7385 - val_loss: 0.1405 - val_accuracy: 0.7282\n",
            "Epoch 4/10\n",
            "3036/3036 - 1s - loss: 0.1063 - accuracy: 0.8119 - val_loss: 0.1428 - val_accuracy: 0.7348\n",
            "Epoch 5/10\n",
            "3036/3036 - 1s - loss: 0.0886 - accuracy: 0.8656 - val_loss: 0.1169 - val_accuracy: 0.8113\n",
            "Epoch 6/10\n",
            "3036/3036 - 1s - loss: 0.0698 - accuracy: 0.8962 - val_loss: 0.1162 - val_accuracy: 0.8259\n",
            "Epoch 7/10\n",
            "3036/3036 - 1s - loss: 0.0585 - accuracy: 0.9147 - val_loss: 0.1263 - val_accuracy: 0.8140\n",
            "Epoch 8/10\n",
            "3036/3036 - 1s - loss: 0.0471 - accuracy: 0.9302 - val_loss: 0.1606 - val_accuracy: 0.8219\n",
            "Epoch 9/10\n",
            "3036/3036 - 1s - loss: 0.0426 - accuracy: 0.9414 - val_loss: 0.1534 - val_accuracy: 0.8140\n",
            "Epoch 10/10\n",
            "3036/3036 - 1s - loss: 0.0177 - accuracy: 0.9783 - val_loss: 0.1627 - val_accuracy: 0.8206\n",
            "758/758 [==============================] - 0s 556us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX_otDrKtboX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1264dd17-4189-4935-fe5b-e44c4dac6445"
      },
      "source": [
        "np.mean(tcn_scores)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8145217588362555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr_J6FWTCYXB",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgmUF8liCa4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95acb111-06fe-4945-8ff2-b50833e22771"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "kim_scores = []\n",
        "kim_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  model=model_kim()\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  #kim_test.append(model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  kim_scores.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 3s - loss: 0.2969 - accuracy: 0.5453 - val_loss: 0.2189 - val_accuracy: 0.5099\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1710 - accuracy: 0.6639 - val_loss: 0.2011 - val_accuracy: 0.5099\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1465 - accuracy: 0.7321 - val_loss: 0.1987 - val_accuracy: 0.5099\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1193 - accuracy: 0.7954 - val_loss: 0.1965 - val_accuracy: 0.5112\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.0956 - accuracy: 0.8465 - val_loss: 0.1918 - val_accuracy: 0.5099\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.0809 - accuracy: 0.8738 - val_loss: 0.2102 - val_accuracy: 0.5125\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0620 - accuracy: 0.9074 - val_loss: 0.1586 - val_accuracy: 0.5942\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0553 - accuracy: 0.9203 - val_loss: 0.1357 - val_accuracy: 0.7444\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0415 - accuracy: 0.9404 - val_loss: 0.1361 - val_accuracy: 0.7457\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0323 - accuracy: 0.9555 - val_loss: 0.1475 - val_accuracy: 0.6957\n",
            "759/759 [==============================] - 0s 315us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 3s - loss: 0.2968 - accuracy: 0.5621 - val_loss: 0.1734 - val_accuracy: 0.5152\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1715 - accuracy: 0.6728 - val_loss: 0.1703 - val_accuracy: 0.5178\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1425 - accuracy: 0.7397 - val_loss: 0.1644 - val_accuracy: 0.5455\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1119 - accuracy: 0.8069 - val_loss: 0.1587 - val_accuracy: 0.6403\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.0883 - accuracy: 0.8517 - val_loss: 0.1516 - val_accuracy: 0.7260\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.0708 - accuracy: 0.8886 - val_loss: 0.1455 - val_accuracy: 0.7075\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0566 - accuracy: 0.9160 - val_loss: 0.1397 - val_accuracy: 0.7141\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0434 - accuracy: 0.9367 - val_loss: 0.1378 - val_accuracy: 0.7246\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0361 - accuracy: 0.9529 - val_loss: 0.1391 - val_accuracy: 0.7299\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0284 - accuracy: 0.9631 - val_loss: 0.1394 - val_accuracy: 0.7352\n",
            "759/759 [==============================] - 0s 317us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 3s - loss: 0.3227 - accuracy: 0.5542 - val_loss: 0.1732 - val_accuracy: 0.5046\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1798 - accuracy: 0.6735 - val_loss: 0.1674 - val_accuracy: 0.5534\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1426 - accuracy: 0.7512 - val_loss: 0.1587 - val_accuracy: 0.7088\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1138 - accuracy: 0.8023 - val_loss: 0.1554 - val_accuracy: 0.7115\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.0927 - accuracy: 0.8484 - val_loss: 0.1612 - val_accuracy: 0.6047\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.0740 - accuracy: 0.8840 - val_loss: 0.1537 - val_accuracy: 0.6469\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0581 - accuracy: 0.9087 - val_loss: 0.1371 - val_accuracy: 0.7378\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0494 - accuracy: 0.9242 - val_loss: 0.1291 - val_accuracy: 0.7484\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0381 - accuracy: 0.9440 - val_loss: 0.1381 - val_accuracy: 0.7022\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0290 - accuracy: 0.9572 - val_loss: 0.1324 - val_accuracy: 0.7418\n",
            "759/759 [==============================] - 0s 307us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 3s - loss: 0.3181 - accuracy: 0.5740 - val_loss: 0.2160 - val_accuracy: 0.5086\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1824 - accuracy: 0.6817 - val_loss: 0.2439 - val_accuracy: 0.5086\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1646 - accuracy: 0.7245 - val_loss: 0.2472 - val_accuracy: 0.5138\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1364 - accuracy: 0.7842 - val_loss: 0.2251 - val_accuracy: 0.5138\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.0986 - accuracy: 0.8425 - val_loss: 0.2118 - val_accuracy: 0.5138\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.0878 - accuracy: 0.8563 - val_loss: 0.1825 - val_accuracy: 0.5178\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.0746 - accuracy: 0.8758 - val_loss: 0.1645 - val_accuracy: 0.5718\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.0669 - accuracy: 0.8972 - val_loss: 0.1462 - val_accuracy: 0.6733\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0604 - accuracy: 0.9071 - val_loss: 0.1369 - val_accuracy: 0.7299\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0536 - accuracy: 0.9213 - val_loss: 0.1358 - val_accuracy: 0.7220\n",
            "759/759 [==============================] - 0s 313us/sample\n",
            "Train on 3036 samples, validate on 758 samples\n",
            "Epoch 1/10\n",
            "3036/3036 - 3s - loss: 0.2711 - accuracy: 0.5715 - val_loss: 0.1891 - val_accuracy: 0.5092\n",
            "Epoch 2/10\n",
            "3036/3036 - 1s - loss: 0.1785 - accuracy: 0.6420 - val_loss: 0.2189 - val_accuracy: 0.5092\n",
            "Epoch 3/10\n",
            "3036/3036 - 1s - loss: 0.1521 - accuracy: 0.6970 - val_loss: 0.2222 - val_accuracy: 0.5092\n",
            "Epoch 4/10\n",
            "3036/3036 - 1s - loss: 0.1302 - accuracy: 0.7572 - val_loss: 0.2204 - val_accuracy: 0.5092\n",
            "Epoch 5/10\n",
            "3036/3036 - 1s - loss: 0.1055 - accuracy: 0.8116 - val_loss: 0.1957 - val_accuracy: 0.5106\n",
            "Epoch 6/10\n",
            "3036/3036 - 1s - loss: 0.0987 - accuracy: 0.8304 - val_loss: 0.1928 - val_accuracy: 0.5106\n",
            "Epoch 7/10\n",
            "3036/3036 - 1s - loss: 0.0886 - accuracy: 0.8643 - val_loss: 0.1772 - val_accuracy: 0.5317\n",
            "Epoch 8/10\n",
            "3036/3036 - 1s - loss: 0.0760 - accuracy: 0.8778 - val_loss: 0.1642 - val_accuracy: 0.5726\n",
            "Epoch 9/10\n",
            "3036/3036 - 1s - loss: 0.0682 - accuracy: 0.8949 - val_loss: 0.1551 - val_accuracy: 0.6266\n",
            "Epoch 10/10\n",
            "3036/3036 - 1s - loss: 0.0637 - accuracy: 0.8992 - val_loss: 0.1565 - val_accuracy: 0.6346\n",
            "758/758 [==============================] - 0s 316us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-3gnxQNthHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7fe0a97d-d6bb-488b-f376-65b91b5466dd"
      },
      "source": [
        "np.mean(kim_scores)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6962500126109302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl7x9txIrSRr",
        "colab_type": "text"
      },
      "source": [
        "##GRU_CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl6lTvncrTai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d2095c8-8b6b-4991-bec4-c93d8452ffa4"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "grucnn_scores = []\n",
        "grucnn_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  model=model_gru_cnn()\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  #grucnn_test.append(model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  grucnn_scores.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 5s - loss: 0.1720 - accuracy: 0.5522 - val_loss: 0.1669 - val_accuracy: 0.5982\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1599 - accuracy: 0.6511 - val_loss: 0.1492 - val_accuracy: 0.6825\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1504 - accuracy: 0.6791 - val_loss: 0.1350 - val_accuracy: 0.7325\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1371 - accuracy: 0.7265 - val_loss: 0.1362 - val_accuracy: 0.6785\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.1298 - accuracy: 0.7367 - val_loss: 0.1203 - val_accuracy: 0.7681\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.1253 - accuracy: 0.7526 - val_loss: 0.1195 - val_accuracy: 0.7866\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.1179 - accuracy: 0.7763 - val_loss: 0.1168 - val_accuracy: 0.7866\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.1124 - accuracy: 0.7954 - val_loss: 0.1145 - val_accuracy: 0.7813\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.1051 - accuracy: 0.8138 - val_loss: 0.1087 - val_accuracy: 0.8155\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0968 - accuracy: 0.8293 - val_loss: 0.1059 - val_accuracy: 0.8248\n",
            "759/759 [==============================] - 1s 925us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 5s - loss: 0.1719 - accuracy: 0.5213 - val_loss: 0.1675 - val_accuracy: 0.6245\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1637 - accuracy: 0.6132 - val_loss: 0.1525 - val_accuracy: 0.6706\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1470 - accuracy: 0.6893 - val_loss: 0.1402 - val_accuracy: 0.7062\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1359 - accuracy: 0.7206 - val_loss: 0.1370 - val_accuracy: 0.7220\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.1269 - accuracy: 0.7440 - val_loss: 0.1366 - val_accuracy: 0.7365\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.1203 - accuracy: 0.7703 - val_loss: 0.1266 - val_accuracy: 0.7484\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.1123 - accuracy: 0.7868 - val_loss: 0.1211 - val_accuracy: 0.7655\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.1066 - accuracy: 0.8020 - val_loss: 0.1226 - val_accuracy: 0.7997\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0976 - accuracy: 0.8277 - val_loss: 0.1245 - val_accuracy: 0.7484\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0943 - accuracy: 0.8366 - val_loss: 0.1190 - val_accuracy: 0.8103\n",
            "759/759 [==============================] - 1s 947us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 5s - loss: 0.1719 - accuracy: 0.5555 - val_loss: 0.1681 - val_accuracy: 0.5995\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1637 - accuracy: 0.6191 - val_loss: 0.1576 - val_accuracy: 0.6548\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1499 - accuracy: 0.6705 - val_loss: 0.1397 - val_accuracy: 0.7036\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1384 - accuracy: 0.7133 - val_loss: 0.1356 - val_accuracy: 0.7299\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.1282 - accuracy: 0.7282 - val_loss: 0.1258 - val_accuracy: 0.7549\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.1213 - accuracy: 0.7522 - val_loss: 0.1304 - val_accuracy: 0.7668\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.1148 - accuracy: 0.7845 - val_loss: 0.1113 - val_accuracy: 0.7852\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.1098 - accuracy: 0.7967 - val_loss: 0.1088 - val_accuracy: 0.8182\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.1012 - accuracy: 0.8247 - val_loss: 0.1070 - val_accuracy: 0.8221\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0977 - accuracy: 0.8244 - val_loss: 0.1061 - val_accuracy: 0.8261\n",
            "759/759 [==============================] - 1s 950us/sample\n",
            "Train on 3035 samples, validate on 759 samples\n",
            "Epoch 1/10\n",
            "3035/3035 - 4s - loss: 0.1723 - accuracy: 0.5456 - val_loss: 0.1644 - val_accuracy: 0.6219\n",
            "Epoch 2/10\n",
            "3035/3035 - 1s - loss: 0.1634 - accuracy: 0.6224 - val_loss: 0.1491 - val_accuracy: 0.6970\n",
            "Epoch 3/10\n",
            "3035/3035 - 1s - loss: 0.1467 - accuracy: 0.6926 - val_loss: 0.1325 - val_accuracy: 0.7312\n",
            "Epoch 4/10\n",
            "3035/3035 - 1s - loss: 0.1377 - accuracy: 0.7094 - val_loss: 0.1271 - val_accuracy: 0.7497\n",
            "Epoch 5/10\n",
            "3035/3035 - 1s - loss: 0.1264 - accuracy: 0.7460 - val_loss: 0.1163 - val_accuracy: 0.7787\n",
            "Epoch 6/10\n",
            "3035/3035 - 1s - loss: 0.1179 - accuracy: 0.7792 - val_loss: 0.1156 - val_accuracy: 0.7615\n",
            "Epoch 7/10\n",
            "3035/3035 - 1s - loss: 0.1151 - accuracy: 0.7832 - val_loss: 0.1044 - val_accuracy: 0.8235\n",
            "Epoch 8/10\n",
            "3035/3035 - 1s - loss: 0.1039 - accuracy: 0.8158 - val_loss: 0.1015 - val_accuracy: 0.8340\n",
            "Epoch 9/10\n",
            "3035/3035 - 1s - loss: 0.0962 - accuracy: 0.8297 - val_loss: 0.1058 - val_accuracy: 0.8340\n",
            "Epoch 10/10\n",
            "3035/3035 - 1s - loss: 0.0930 - accuracy: 0.8435 - val_loss: 0.1019 - val_accuracy: 0.8287\n",
            "759/759 [==============================] - 1s 916us/sample\n",
            "Train on 3036 samples, validate on 758 samples\n",
            "Epoch 1/10\n",
            "3036/3036 - 5s - loss: 0.1717 - accuracy: 0.5395 - val_loss: 0.1646 - val_accuracy: 0.6174\n",
            "Epoch 2/10\n",
            "3036/3036 - 1s - loss: 0.1636 - accuracy: 0.6163 - val_loss: 0.1544 - val_accuracy: 0.6689\n",
            "Epoch 3/10\n",
            "3036/3036 - 1s - loss: 0.1495 - accuracy: 0.6789 - val_loss: 0.1409 - val_accuracy: 0.6966\n",
            "Epoch 4/10\n",
            "3036/3036 - 1s - loss: 0.1375 - accuracy: 0.7184 - val_loss: 0.1298 - val_accuracy: 0.7348\n",
            "Epoch 5/10\n",
            "3036/3036 - 1s - loss: 0.1279 - accuracy: 0.7451 - val_loss: 0.1270 - val_accuracy: 0.7493\n",
            "Epoch 6/10\n",
            "3036/3036 - 1s - loss: 0.1206 - accuracy: 0.7727 - val_loss: 0.1189 - val_accuracy: 0.7902\n",
            "Epoch 7/10\n",
            "3036/3036 - 1s - loss: 0.1142 - accuracy: 0.7872 - val_loss: 0.1159 - val_accuracy: 0.7942\n",
            "Epoch 8/10\n",
            "3036/3036 - 1s - loss: 0.1023 - accuracy: 0.8169 - val_loss: 0.1143 - val_accuracy: 0.7995\n",
            "Epoch 9/10\n",
            "3036/3036 - 1s - loss: 0.0985 - accuracy: 0.8215 - val_loss: 0.1180 - val_accuracy: 0.7942\n",
            "Epoch 10/10\n",
            "3036/3036 - 1s - loss: 0.0919 - accuracy: 0.8360 - val_loss: 0.1134 - val_accuracy: 0.8232\n",
            "758/758 [==============================] - 1s 925us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIiSnpMKtop7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea45a36e-a85f-4e3a-849a-07835865bb91"
      },
      "source": [
        "np.mean(grucnn_scores)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.821623196296424"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bXDiFxJH5Ny",
        "colab_type": "text"
      },
      "source": [
        "#**Result**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXd8VkdPhAq2",
        "colab_type": "text"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnC41n_HRKQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_scores=np.average(np.array(gru_scores))\n",
        "atten_scores=np.average(np.array(atten_scores))\n",
        "tcn_scores=np.average(np.array(tcn_scores))\n",
        "kim_scores=np.average(np.array(kim_scores))\n",
        "gru_scores1=np.average\n",
        "(np.array(gru_scores1))\n",
        "grucnn_scores=np.mean(np.array(grucnn_scores))\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBp341Qog_uv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "780a0e81-dc98-49b3-ca9f-df255feaa225"
      },
      "source": [
        "print('f1 score of count vec' ,cv_score)\n",
        "print('f1 score of word tfidf' ,tfw_score)\n",
        "print('f1 score of char tfidf' ,tfc_score)\n",
        "\n",
        "print('f1 score of RNN' ,gru_scores)\n",
        "print('f1 score of gated attention',atten_scores )\n",
        "print('f1 score of tcn',tcn_scores)\n",
        "print('f1 score of kim',kim_scores)\n",
        "print('f1 score of gru_1',gru_scores1)\n",
        "print('f1 score of gru_cnn',grucnn_scores)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score of count vec 0.8540543614027971\n",
            "f1 score of word tfidf 0.845548565812291\n",
            "f1 score of char tfidf 0.8540530522045847\n",
            "f1 score of RNN 0.7934497667600902\n",
            "f1 score of gated attention 0.794886579582516\n",
            "f1 score of tcn 0.8145217588362555\n",
            "f1 score of kim 0.6962500126109302\n",
            "f1 score of gru_1 <function average at 0x7fb66455eb70>\n",
            "f1 score of gru_cnn 0.821623196296424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipijYwvjJPyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kim_test_avg=np.mean(np.array(kim_test),axis=0)\n",
        "gru_test_avg=np.mean(np.array(gru_test),axis=0)\n",
        "atten_test_avg=np.mean(np.array(atten_test),axis=0)\n",
        "tcn_test_avg=np.mean(np.array(tcn_test),axis=0)\n",
        "grucnn_test_avg=np.mean(np.array(grucnn_test),axis=0)\n",
        "gru_test1_avg=np.mean(np.array(gru_test1),axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAMx_NI2jltK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3e100a17-2f15-4cd3-b85f-e663d5bacaba"
      },
      "source": [
        "kim_test[0].shape,cv_test.shape,kim_test_avg.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3887,), (3887,), (3887,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ8CR7s1Qe18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "aad52364-6e01-4493-f0f4-65ce2d739986"
      },
      "source": [
        "print(cv_test[5:15].round())\n",
        "print(tfw_test[5:15].round())\n",
        "print(tfc_test[5:15].round())\n",
        "print(gru_test_avg[5:15].round())\n",
        "print(atten_test_avg[5:15].round())\n",
        "print(kim_test_avg[5:15].round())\n",
        "print(tcn_test_avg[5:15].round())\n",
        "print(grucnn_test_avg[5:15].round())\n",
        "print(gru_test1_avg[5:15].round())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW1OugTMEpZg",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6VT0aVcUIhm",
        "colab_type": "text"
      },
      "source": [
        "we will choose only those, having f1 greater than 0.7. Once they are selected, we will decode labels, and keep label according to mod"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wmQlS5LkZLi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b8a5db67-3b2a-44f3-923c-c6f694677d2f"
      },
      "source": [
        "wt=gru_scores+atten_scores+cv_score+tfw_score+tfc_score+tcn_scores+kim_scores+gru_scores1+grucnn_scores\n",
        "wt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.563347387547225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkCLYtxOcXCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#i am bit changing the distribution in order to give more weightage to ml than dl\n",
        "y_test=gru_scores/wt * gru_test_avg + atten_scores/wt * atten_test_avg + cv_score/wt * cv_test + tfw_score/wt *tfw_test + tfc_score/wt *tfc_test +kim_scores/wt * kim_test_avg + tcn_scores/wt *tcn_test_avg + gru_scores1/wt *gru_test1_avg +grucnn_scores/wt*grucnn_test_avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzRAIebNSpMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "83f0e989-b3f9-457a-aa99-866322e33368"
      },
      "source": [
        "y_test[5:15].round()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSAGwvs6Uyn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/drive/My Drive/dataset/OffenseEval2020/data/English/olid_ensemble.npy',y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Pu0LvuZIf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(ids,y_test):\n",
        "  y_test[y_test>0.5]=1\n",
        "  y_test[y_test<0.5]=0\n",
        "  y_test=y_test.astype('int16').ravel()\n",
        "\n",
        "  y_test=le.inverse_transform(y_test)\n",
        "  y_test=pd.DataFrame(y_test,columns=['label'])\n",
        "  y_test=pd.concat([ids, y_test['label']], axis=1)\n",
        "  return y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PgV77IYZRGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test=decode(ids,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8avMmBQvb_IR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "7faed138-4a8f-4277-f92d-299a43e21617"
      },
      "source": [
        "y_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A4</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id label\n",
              "0  A0   OFF\n",
              "1  A1   OFF\n",
              "2  A2   NOT\n",
              "3  A3   NOT\n",
              "4  A4   NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl57zICXM4c6",
        "colab_type": "text"
      },
      "source": [
        "# Submit file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LkCxvtfEnpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHTCw4_jP_tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test.to_csv('/content/disaster.csv',index=False,header=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tPo96DUz_EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwKb7_NBWjAv",
        "colab_type": "text"
      },
      "source": [
        "# Reset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Xi3s2KWlKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import keras\n",
        "# keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T39YK5rbQBoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}